{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20220718EntrenamientoSabor.ipynb","provenance":[{"file_id":"1IvYvsdSkdrSF01LNppJIKgQJpoUsnsqE","timestamp":1657423299943},{"file_id":"1h5lIuzm3HJSHRqV-OeDEtqos8mFrZtyx","timestamp":1657423236966},{"file_id":"1P5m5lFrlQtHsw85v5mWhcvO7PNJOgP90","timestamp":1657423146961},{"file_id":"1YzpqNPAOLX5PGnnSgr56iNGNQPSDVDjS","timestamp":1657422995852},{"file_id":"1IE874SJMaLtmHGPi8-OyGBxI9FYz97lz","timestamp":1657422712654},{"file_id":"1Xft2wdYTuv3655Sh63IQIcvE6YFU948N","timestamp":1657421369845},{"file_id":"1_NpQSAVMZRIYKrCTefRdvj08CTtBsSmO","timestamp":1657420111479},{"file_id":"1q4rMjTSzecwGSpKbaYRi4FqKHmVaHhu0","timestamp":1657315890956},{"file_id":"1RlC43FFjtyfAfwBtyZcuZKzLpXEoOmNO","timestamp":1656292223731},{"file_id":"1huGdll4NZyqsjNPHbbHxA4Ba_CnXLU_V","timestamp":1654732496996},{"file_id":"1cWhR3-iQYQbj7LQgwEMjKCYGKPuX5NRJ","timestamp":1652471440267},{"file_id":"1cYbdIzhjeWw3lqZ1at2CL2ik_U-NvAhQ","timestamp":1590719736666}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"4ZeyRjUbTkvm"},"source":["# Código para dataset de café con datos de Sabor  y con pipelines\n","# Luz Adriana Plazas Pemberthy 2190651\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#instalación de librerías no contenidas en colab\n","# !pip install mglearn\n","# import mglearn"],"metadata":{"id":"w0wRk2V_wmMu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXkMH_LwNm8N"},"source":["**Cargar las librerías básicas y el dataset al programa**\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"x__kQ7TTR4B5"},"source":["#importar librerías basicas\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","#importar métodos de preprocesamiento\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import Normalizer\n","from sklearn.preprocessing import RobustScaler\n","import statsmodels.formula.api as sm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import r2_score\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oFcSdF_iUPjf"},"source":["#subir archivo\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"faMpKI0kUTth"},"source":["# Cargar el dataset\n","Coffee = pd.read_csv(\"df_Sabor.csv\", sep=',')\n","# Convert string target vector to integer\n","\n","X = Coffee.loc[:,'Muestras':'Phad']\n","y = Coffee.loc[:,'Sabor']\n","#Revisar el tamaño del dataset cargado\n","print ('X')\n","print (X.shape)\n","print ('y')\n","print (y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jx8pW58YYOfZ"},"source":["# Se realiza la separación del dataset  #(ctrl+/) comentario\n","# B Separar en train y test\n","X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1)\n","# print(\"per-feature minimum before scaling:\\n {}\".format(X_train.min(axis=0)))\n","# print(\"per-feature maximum before scaling:\\n {}\".format(X_train.max(axis=0)))\n","# print(\"target minimum before scaling:\\n {}\".format(y_train.min(axis=0)))\n","# print(\"target maximum before scaling:\\n {}\".format(y_train.max(axis=0)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRvEx45qc7qU"},"source":["Pruebas iniciales con los modelos básicos de regresión"]},{"cell_type":"code","metadata":{"id":"IBbFtTS7OGHk"},"source":["###pruebas de regresión  básica\n","# Regresion lineal LS\n","from sklearn.linear_model import LinearRegression\n","lrLS = LinearRegression()\n","lrLS.fit(X_train, y_train)\n","print(\"Train set score linear regression: {:.2f}\".format(lrLS.score(X_train, y_train)))\n","print(\"Test set score linear regression: {:.2f}\".format(lrLS.score(X_test, y_test)))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" Train_set=X_train\n"," Train_set['Sabor']=y_train\n","#  Modelo=sm.ols(formula='Sabor ~ Muestras + Pha + Phme + TDSa + Phdif + Phmax + Phv + Phd + Alcohola + Phf + Co2max + Phmo + Co2dif + TDSmind + Co2d + Alcoholmax + Temp1dif + Alcoholdifd + Co2v + Alcoholdif + Alcoholmaxd + Temp1max + Temp1maxd + Temp2dif + Temp1a + Co2maxd + Temp1me + Co2difd + Alcoholi + Alcoholmin + Phdd + TDSf + Temp2f + Phvd + Alcoholf + Temp2min + TDSmaxd + TDSvd + TDSdifd + Temp2ad + TDSdd + Alcoholv + Alcohold + Co2f + TDSv + TDSd + Temp1ad + Alcoholad + TDSad + Co2ad + Phad', data= Train_set)\n","#  Modelo=sm.ols(formula='Sabor ~ Muestras + Pha + Phme + TDSa + Phdif + Phmax + Phv + Phd + Alcohola + Phf + Alcoholv + Alcohold + Co2f + TDSv + TDSd + Temp1ad + Alcoholad + TDSad + Co2ad + Phad', data= Train_set)\n","#  Modelo=sm.ols(formula='Sabor ~ Muestras + Pha + Co2ad + Alcohola + TDSa + Temp1ad + Temp2ad', data= Train_set) #0.999 0.93\n","#  Modelo=sm.ols(formula='Sabor ~ Muestras + Pha', data= Train_set) #0.99 0.95\n","# Modelo=sm.ols(formula='Sabor ~ Muestras + Pha + Co2ad', data= Train_set) #0.99 0.91\n"," Modelo=sm.ols(formula='Sabor ~ Muestras + Pha + Co2max + Alcohola + Temp1ad', data= Train_set) #0.99 0.98\n"," Fitted=Modelo.fit()\n"," print(Fitted.summary())"],"metadata":{"id":"QdkQS3THxgdL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Prediccion=Fitted.predict(X_test) #guardar la predicción y luego sacar el error\n","print('\\n\\n MSE:\\t',mean_squared_error(y_test,Prediccion))\n","print('\\n MAE:\\t',mean_absolute_error(y_test,Prediccion))\n","print('\\n R2 Score test:\\t',r2_score(y_test,Prediccion),'\\n')"],"metadata":{"id":"YSiZ7fckywc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Coffee = pd.read_csv(\"df_Sabor.csv\", sep=',')\n","X = Coffee.loc[:,'Muestras':'Phad']\n","y = Coffee.loc[:,'Sabor']\n","#split\n","X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1)\n","#split manual\n","# X_train=X.loc[[0,1,2,4,5,6,8,9,10,12,13,14]]\n","# X_test=X.loc[[3,7,11,15]]\n","# y_train=y.loc[[0,1,2,4,5,6,8,9,10,12,13,14]]\n","# y_test=y.loc[[3,7,11,15]]\n","\n","col_sec=['Muestras', 'Pha', 'Co2max', 'Alcohola']\n","# col_sec=['Muestras' , 'Pha' , 'Co2ad' , 'Alcohola' , 'TDSa' , 'Temp1ad' , 'Temp2ad']\n","X_train=X_train[col_sec]\n","X_test=X_test[col_sec]"],"metadata":{"id":"5-bHKSEJyz1g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lrLS = LinearRegression()\n","lrLS.fit(X_train, y_train)\n","print(\"Train set score linear regression: {:.2f}\".format(lrLS.score(X_train, y_train)))\n","print(\"Test set score linear regression: {:.2f}\".format(lrLS.score(X_test, y_test)))"],"metadata":{"id":"mUklcoEQzFR1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Prueba mejor modelo"],"metadata":{"id":"loEmezovUiK7"}},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import make_pipeline"],"metadata":{"id":"1BDjZPkKUkFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# regresión lineal con Ridge\n","from sklearn.linear_model import Ridge\n","ridge = Ridge().fit(X_train, y_train)\n","print(\"Training set score Ridge regression: {:.2f}\".format(ridge.score(X_train, y_train)))\n","print(\"Test set score Ridge regression: {:.2f}\".format(ridge.score(X_test, y_test)))\n","#Optimizacion de hiperparámetros con Pipeline and GridSearch\n","# param_grid = {'alpha': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n","param_grid = {'ridge__alpha': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n","print (\"\\n\")\n","# MINMAX scaler\n","pipe = make_pipeline(MinMaxScaler(), Ridge())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"RIDGE MinMax Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Standar scaler\n","pipe = make_pipeline(StandardScaler(), Ridge())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"RIDGE STANDAR Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Normalizer scaler\n","pipe = make_pipeline(Normalizer(), Ridge())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"RIDGE Normailzer Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","\n","# Robust scaler\n","pipe = make_pipeline(RobustScaler(), Ridge())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"RIDGE Robust Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n"],"metadata":{"id":"9BpGqMq6Qotc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Regresión lineal con lasso\n","from sklearn.linear_model import Lasso\n","lasso = Lasso(max_iter=10000).fit(X_train, y_train)\n","print(\"Training set score Lasso Regression: {:.2f}\".format(lasso.score(X_train, y_train)))\n","print(\"Test set score Lasso Regression: {:.2f}\".format(lasso.score(X_test, y_test)))\n","print(\"Number of features used Lasso Regression:\", np.sum(lasso.coef_ != 0))\n","\n","#Optimizacion de hiperparámetros con Pipeline and GridSearch\n","\n","param_grid = {'lasso__alpha': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000], 'lasso__tol': [0.00001,0.0001,0.001]}\n","# MINMAX scaler\n","pipe = make_pipeline(MinMaxScaler(), Lasso())\n","pipe.get_params().keys()\n","# pipe = make_pipeline(MinMaxScaler(), Lasso())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"Lasso MinMax Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Standar scaler\n","pipe = make_pipeline(StandardScaler(), Lasso())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"Lasso STANDAR Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Normalizer scaler\n","pipe = make_pipeline(Normalizer(), Lasso())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"Lasso Normailzer Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","\n","# Robust scaler\n","pipe = make_pipeline(RobustScaler(), Lasso())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"Lasso Robust Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")"],"metadata":{"id":"lLRUVNh_Qwht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Bayesian Ridge Regression\n","from sklearn import linear_model\n","Bay= linear_model.BayesianRidge()\n","Bay.fit(X_train, y_train)\n","print(\"Training set score Bayesian Ridge Regression: {:.2f}\".format(Bay.score(X_train, y_train)))\n","print(\"Test set score Bayesian Ridge Regression: {:.2f}\".format(Bay.score(X_test, y_test)))\n","print (\"\\n\")\n","#print (\"Los modelos básicos han arrojado malos resultados\")\n","#Optimizacion de hiperparámetros con Pipeline and GridSearch\n","\n","param_grid = {'bayesianridge__alpha_1': [1e-2, 0.1, 1, 10, 100, 1000], 'bayesianridge__tol': [0.00001,0.0001,0.001]}\n","# MINMAX scaler\n","pipe = make_pipeline(MinMaxScaler(), linear_model.BayesianRidge())\n","pipe.get_params().keys()\n","# pipe = make_pipeline(MinMaxScaler(), Lasso())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"BayesianRidge MinMax Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Standar scaler\n","pipe = make_pipeline(StandardScaler(), linear_model.BayesianRidge())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"BayesianRidge STANDAR Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Normalizer scaler\n","pipe = make_pipeline(Normalizer(), linear_model.BayesianRidge())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"BayesianRidge Normailzer Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","\n","# Robust scaler\n","pipe = make_pipeline(RobustScaler(), linear_model.BayesianRidge())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"BayesianRidge Robust Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")"],"metadata":{"id":"ApHh-HKCQ0e8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Stochastic Gradient Descent SGDRegressor \n","from sklearn.linear_model import SGDRegressor\n","SGDreg = SGDRegressor(max_iter=1000, tol=1e-3)\n","SGDreg.fit (X_train, y_train)\n","print(\"Training set score SGD Regressor: {:.2f}\".format(SGDreg.score(X_train, y_train)))\n","print(\"Test set score SGD Regressor: {:.2f}\".format(SGDreg.score(X_test, y_test)))\n","\n","#Optimizacion de hiperparámetros con Pipeline and GridSearch\n","\n","param_grid = {'sgdregressor__alpha': [0.0001, 0.001, 0.01, 0.1, 10, 100],\n","              'sgdregressor__tol': [0.0001,0.001, 0.01, 0.1, 1, 10, 100,1000]}\n","\n","# pipe = make_pipeline(MinMaxScaler(), SGDRegressor(max_iter=10000))\n","# pipe.get_params().keys()\n","\n","# MINMAX scaler\n","pipe = make_pipeline(MinMaxScaler(), SGDRegressor(max_iter=10000))\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"SGDRegressor MinMax Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Standar scaler\n","pipe = make_pipeline(StandardScaler(), SGDRegressor(max_iter=10000))\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"SGDRegressor STANDAR Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Normalizer scaler\n","pipe = make_pipeline(Normalizer(), SGDRegressor(max_iter=10000))\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"SGDRegressor Normailzer Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","\n","# Robust scaler\n","pipe = make_pipeline(RobustScaler(), SGDRegressor(max_iter=10000))\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"SGDRegressor Robust Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","# print (\"\\n\")"],"metadata":{"id":"TDImszr2Q8hr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Linear Support Vector Regression\n","from sklearn.svm import LinearSVR\n","from sklearn.svm import SVR\n","svr = SVR(C=16)\n","svr.fit(X_train, y_train)\n","print(\"Training set score: {:.2f}\".format(svr.score(X_train, y_train)))\n","print(\"Test set score: {:.2f}\".format(svr.score(X_test, y_test)))\n","\n","param_grid = {'svr__C': [0.001, 0.01, 0.1, 1, 10, 100,1000],\n","              'svr__gamma': [0.0001,0.001, 0.01, 0.1, 1, 10, 100,1000]}\n","# pipe = make_pipeline(MinMaxScaler(), SVR())\n","# pipe.get_params().keys()\n","\n","# MINMAX scaler\n","pipe = make_pipeline(MinMaxScaler(), SVR())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"SVR MinMax Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Standar scaler\n","pipe = make_pipeline(StandardScaler(),  SVR())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"SVR STANDAR Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Normalizer scaler\n","pipe = make_pipeline(Normalizer(),  SVR())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"SVR Normailzer Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","\n","# Robust scaler\n","pipe = make_pipeline(RobustScaler(),  SVR())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\"SVR Robust Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")"],"metadata":{"id":"RjmC3Ui2RACN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Árboles de decisión regresión\n","from sklearn.tree import DecisionTreeRegressor\n","regressor = DecisionTreeRegressor(max_depth=4)\n","regressor.fit(X_train, y_train)\n","print(\"Training set score: {:.2f}\".format(regressor.score(X_train, y_train)))\n","print(\"Test set score: {:.2f}\".format(regressor.score(X_test, y_test)))\n","\n","param_grid = {'decisiontreeregressor__max_depth': [1,2,3,4,5,6,7,8],'decisiontreeregressor__min_samples_leaf': [1,2,3,4,5,6,7,8]}\n","# pipe = make_pipeline(MinMaxScaler(), DecisionTreeRegressor())\n","# pipe.get_params().keys()\n","\n","# MINMAX scaler\n","pipe = make_pipeline(MinMaxScaler(), DecisionTreeRegressor())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\" DecisionTreeRegressor MinMax Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Standar scaler\n","pipe = make_pipeline(StandardScaler(),  DecisionTreeRegressor())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\" DecisionTreeRegressor STANDAR Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Normalizer scaler\n","pipe = make_pipeline(Normalizer(),  DecisionTreeRegressor())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\" DecisionTreeRegressor Normailzer Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","\n","# Robust scaler\n","pipe = make_pipeline(RobustScaler(),  DecisionTreeRegressor())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\" DecisionTreeRegressor Robust Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")"],"metadata":{"id":"SUZ_cMQSRDwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Random forest regressor\n","\n","from sklearn.ensemble import RandomForestRegressor\n","Forest = RandomForestRegressor(n_estimators=5)\n","Forest.fit(X_train,y_train)\n","print(\"Training set score: {:.2f}\".format(Forest.score(X_train, y_train)))\n","print(\"Test set score: {:.2f}\".format(Forest.score(X_test, y_test)))\n","\n","# param_grid = {'randomforestregressor__max_depth': [1,2,3,4,5,6,7,8],'randomforestregressor__min_samples_leaf': [1,2,3,4,5,6,7,8],'randomforestregressor__n_estimators':[1,2,3,4,5,6]}\n","# param_grid = {'randomforestregressor__min_samples_leaf': [1,2,3,4,5,6,7,8],'randomforestregressor__n_estimators':[1,2,3,4,5,6]}\n","param_grid = {'randomforestregressor__n_estimators':[1,2,3,4,5,6]}\n","\n","# pipe = make_pipeline(MinMaxScaler(), RandomForestRegressor())\n","# pipe.get_params().keys()\n","\n","# MINMAX scaler\n","pipe = make_pipeline(MinMaxScaler(), RandomForestRegressor())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\" RandomForestRegressor MinMax Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Standar scaler\n","pipe = make_pipeline(StandardScaler(),  RandomForestRegressor())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\" RandomForestRegressor STANDAR Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","# Normalizer scaler\n","pipe = make_pipeline(Normalizer(),  RandomForestRegressor())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\" RandomForestRegressor Normailzer Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","print (\"\\n\")\n","\n","\n","# Robust scaler\n","pipe = make_pipeline(RobustScaler(),  RandomForestRegressor())\n","grid = GridSearchCV(pipe, param_grid, cv=5)\n","grid.fit(X_train, y_train)\n","print(\" RandomForestRegressor Robust Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))\n","print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n","print(\"Best parameters: {}\".format(grid.best_params_))\n","# print (\"\\n\")"],"metadata":{"id":"mM4FcZa2RInH"},"execution_count":null,"outputs":[]}]}